{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdL+nGgYMSOHHh/HZf7veO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swapnabanoth/001_BDA_Assignment/blob/main/BDA_001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFDVhxBk-6t6",
        "outputId": "323f2d3c-1830-4fcc-c803-05af5beda7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Step 1: Create Spark session\n",
        "spark = SparkSession.builder.appName(\"IrisClassification\").getOrCreate()\n",
        "\n",
        "# Step 2: Load dataset\n",
        "# You can replace this with your own CSV path\n",
        "data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
        "\n",
        "# Downloading data and saving locally (if needed)\n",
        "import pandas as pd\n",
        "iris_df = pd.read_csv(data_url, names=columns)\n",
        "iris_df.to_csv(\"iris.csv\", index=False)\n",
        "\n",
        "# Load into Spark\n",
        "df = spark.read.csv(\"iris.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Step 3: Preprocess data\n",
        "# Let's convert this into a binary classification problem: 'Iris-setosa' vs others\n",
        "df = df.withColumn(\"label\", (df[\"species\"] == \"Iris-setosa\").cast(\"integer\"))\n",
        "\n",
        "# Features into a single vector\n",
        "feature_columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "df = assembler.transform(df)\n",
        "\n",
        "# Step 4: Split dataset\n",
        "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Step 5: Build and train model\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "model = lr.fit(train_data)\n",
        "\n",
        "# Step 6: Make predictions\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Step 7: Evaluate model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Optional: Show some predictions\n",
        "predictions.select(\"features\", \"label\", \"prediction\").show(5)\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIBcs2sH9SIV",
        "outputId": "03abd58d-3b38-49b7-af26-06e98e4410a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n",
            "+-----------------+-----+----------+\n",
            "|         features|label|prediction|\n",
            "+-----------------+-----+----------+\n",
            "|[4.4,3.0,1.3,0.2]|    1|       1.0|\n",
            "|[4.6,3.2,1.4,0.2]|    1|       1.0|\n",
            "|[4.6,3.6,1.0,0.2]|    1|       1.0|\n",
            "|[4.8,3.1,1.6,0.2]|    1|       1.0|\n",
            "|[4.9,3.1,1.5,0.1]|    1|       1.0|\n",
            "+-----------------+-----+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Step 1: Spark Session\n",
        "spark = SparkSession.builder.appName(\"MovieRecommendation\").getOrCreate()\n",
        "\n",
        "# Step 2: Load dataset\n",
        "# MovieLens 100k dataset: userId, movieId, rating, timestamp\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "\n",
        "# Download MovieLens 100k\n",
        "ml_url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "urllib.request.urlretrieve(ml_url, \"ml-latest-small.zip\")\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"ml-latest-small.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "# Read ratings into Spark\n",
        "ratings_df = spark.read.csv(\"ml-latest-small/ratings.csv\", header=True, inferSchema=True)\n",
        "ratings_df = ratings_df.select(\"userId\", \"movieId\", \"rating\")\n",
        "\n",
        "# Step 3: Train-test split\n",
        "train_data, test_data = ratings_df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Step 4: ALS model\n",
        "als = ALS(\n",
        "    maxIter=10,\n",
        "    regParam=0.1,\n",
        "    userCol=\"userId\",\n",
        "    itemCol=\"movieId\",\n",
        "    ratingCol=\"rating\",\n",
        "    coldStartStrategy=\"drop\"  # drop NaN predictions\n",
        ")\n",
        "model = als.fit(train_data)\n",
        "\n",
        "# Step 5: Predictions\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"\\nRoot-mean-square error (RMSE): {rmse:.4f}\")\n",
        "\n",
        "# Step 7: Recommend Top 5 Movies for Each User\n",
        "user_recs = model.recommendForAllUsers(5)\n",
        "print(\"\\nTop 5 movie recommendations for sample users:\")\n",
        "user_recs.show(5, truncate=False)\n",
        "\n",
        "# Step 8: Stop Spark session\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3EnHuTpNO0a",
        "outputId": "ac21afc4-3e4b-4d43-9e34-065c0e7a16f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Root-mean-square error (RMSE): 0.8797\n",
            "\n",
            "Top 5 movie recommendations for sample users:\n",
            "+------+-------------------------------------------------------------------------------------------------+\n",
            "|userId|recommendations                                                                                  |\n",
            "+------+-------------------------------------------------------------------------------------------------+\n",
            "|1     |[{132333, 5.896185}, {177593, 5.773418}, {5915, 5.77255}, {8542, 5.668288}, {171495, 5.6276536}] |\n",
            "|2     |[{131724, 4.9002175}, {2693, 4.89408}, {136469, 4.852532}, {78836, 4.72831}, {2936, 4.726223}]   |\n",
            "|3     |[{5048, 5.0585546}, {6835, 4.914627}, {5746, 4.914627}, {5181, 4.8702173}, {4518, 4.8108983}]    |\n",
            "|4     |[{4642, 5.288948}, {132333, 5.1431713}, {26326, 5.045396}, {2300, 5.0337276}, {8542, 5.032188}]  |\n",
            "|5     |[{1188, 4.917164}, {177593, 4.8808775}, {1212, 4.8354225}, {26326, 4.8340344}, {7096, 4.8247476}]|\n",
            "+------+-------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Step 1: Setup Spark\n",
        "# ============================\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"MovieRecommendationALS\").getOrCreate()\n",
        "\n",
        "# ============================\n",
        "# Step 2: Load Dataset\n",
        "# ============================\n",
        "ratings_path = \"/content/ml-latest-small/ratings.csv\"  # <- Change path if needed\n",
        "\n",
        "df = spark.read.csv(ratings_path, header=True, inferSchema=True)\n",
        "df = df.select(\"userId\", \"movieId\", \"rating\")\n",
        "df.show(5)\n",
        "\n",
        "# ============================\n",
        "# Step 3: Train ALS Model\n",
        "# ============================\n",
        "als = ALS(\n",
        "    userCol=\"userId\",\n",
        "    itemCol=\"movieId\",\n",
        "    ratingCol=\"rating\",\n",
        "    maxIter=10,\n",
        "    regParam=0.1,\n",
        "    rank=10,\n",
        "    nonnegative=True,\n",
        "    coldStartStrategy=\"drop\"\n",
        ")\n",
        "\n",
        "model = als.fit(df)\n",
        "\n",
        "# ============================\n",
        "# Step 4: Make Predictions\n",
        "# ============================\n",
        "predictions = model.transform(df)\n",
        "\n",
        "# ============================\n",
        "# Step 5: Evaluate the Model\n",
        "# ============================\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"\\n Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "\n",
        "# ============================\n",
        "# Step 6: Generate Recommendations\n",
        "# ============================\n",
        "userRecs = model.recommendForAllUsers(5)\n",
        "itemRecs = model.recommendForAllItems(5)\n",
        "\n",
        "print(\"\\n Top-5 movie recommendations for users:\")\n",
        "userRecs.select(\"userId\", \"recommendations\").show(5, truncate=False)\n",
        "\n",
        "# ============================\n",
        "# Step 7: Stop Spark\n",
        "# ============================\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "njAPfk4sXpeE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}