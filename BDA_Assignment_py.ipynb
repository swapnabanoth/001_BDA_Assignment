{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9PthwdLBDW8fy713ZpeEc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swapnabanoth/001_BDA_Assignment/blob/main/BDA_Assignment_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDrHjyBUdLJ5"
      },
      "outputs": [],
      "source": [
        "# 1 Build a Classification Model with Spark with a dataset of your choice\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Step 1: Create Spark session\n",
        "spark = SparkSession.builder.appName(\"IrisClassification\").getOrCreate()\n",
        "\n",
        "# Step 2: Load dataset\n",
        "# You can replace this with your own CSV path\n",
        "data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
        "\n",
        "# Downloading data and saving locally (if needed)\n",
        "import pandas as pd\n",
        "iris_df = pd.read_csv(data_url, names=columns)\n",
        "iris_df.to_csv(\"iris.csv\", index=False)\n",
        "\n",
        "# Load into Spark\n",
        "df = spark.read.csv(\"iris.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Step 3: Preprocess data\n",
        "# Let's convert this into a binary classification problem: 'Iris-setosa' vs others\n",
        "df = df.withColumn(\"label\", (df[\"species\"] == \"Iris-setosa\").cast(\"integer\"))\n",
        "\n",
        "# Features into a single vector\n",
        "feature_columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "df = assembler.transform(df)\n",
        "\n",
        "# Step 4: Split dataset\n",
        "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Step 5: Build and train model\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "model = lr.fit(train_data)\n",
        "\n",
        "# Step 6: Make predictions\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Step 7: Evaluate model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Optional: Show some predictions\n",
        "predictions.select(\"features\", \"label\", \"prediction\").show(5)\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()\n",
        "\n",
        "\n",
        "# 2 Build a Clustering Model with Spark with a dataset of your choice\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Step 1: Spark Session\n",
        "spark = SparkSession.builder.appName(\"MovieRecommendation\").getOrCreate()\n",
        "\n",
        "# Step 2: Load dataset\n",
        "# MovieLens 100k dataset: userId, movieId, rating, timestamp\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "\n",
        "# Download MovieLens 100k\n",
        "ml_url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "urllib.request.urlretrieve(ml_url, \"ml-latest-small.zip\")\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"ml-latest-small.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "# Read ratings into Spark\n",
        "ratings_df = spark.read.csv(\"ml-latest-small/ratings.csv\", header=True, inferSchema=True)\n",
        "ratings_df = ratings_df.select(\"userId\", \"movieId\", \"rating\")\n",
        "\n",
        "# Step 3: Train-test split\n",
        "train_data, test_data = ratings_df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Step 4: ALS model\n",
        "als = ALS(\n",
        "    maxIter=10,\n",
        "    regParam=0.1,\n",
        "    userCol=\"userId\",\n",
        "    itemCol=\"movieId\",\n",
        "    ratingCol=\"rating\",\n",
        "    coldStartStrategy=\"drop\"  # drop NaN predictions\n",
        ")\n",
        "model = als.fit(train_data)\n",
        "\n",
        "# Step 5: Predictions\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"\\nRoot-mean-square error (RMSE): {rmse:.4f}\")\n",
        "\n",
        "# Step 7: Recommend Top 5 Movies for Each User\n",
        "user_recs = model.recommendForAllUsers(5)\n",
        "print(\"\\nTop 5 movie recommendations for sample users:\")\n",
        "user_recs.show(5, truncate=False)\n",
        "\n",
        "# Step 8: Stop Spark session\n",
        "spark.stop()\n",
        "\n",
        "\n",
        "# 3 Build a Recommendation Engine with Spark with a dataset of your choice\n",
        "# Step 1: Setup Spark\n",
        "# ============================\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"MovieRecommendationALS\").getOrCreate()\n",
        "\n",
        "# ============================\n",
        "# Step 2: Load Dataset\n",
        "# ============================\n",
        "ratings_path = \"/content/ml-latest-small/ratings.csv\"  # <- Change path if needed\n",
        "\n",
        "df = spark.read.csv(ratings_path, header=True, inferSchema=True)\n",
        "df = df.select(\"userId\", \"movieId\", \"rating\")\n",
        "df.show(5)\n",
        "\n",
        "# ============================\n",
        "# Step 3: Train ALS Model\n",
        "# ============================\n",
        "als = ALS(\n",
        "    userCol=\"userId\",\n",
        "    itemCol=\"movieId\",\n",
        "    ratingCol=\"rating\",\n",
        "    maxIter=10,\n",
        "    regParam=0.1,\n",
        "    rank=10,\n",
        "    nonnegative=True,\n",
        "    coldStartStrategy=\"drop\"\n",
        ")\n",
        "\n",
        "model = als.fit(df)\n",
        "\n",
        "# ============================\n",
        "# Step 4: Make Predictions\n",
        "# ============================\n",
        "predictions = model.transform(df)\n",
        "\n",
        "# ============================\n",
        "# Step 5: Evaluate the Model\n",
        "# ============================\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"\\n Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "\n",
        "# ============================\n",
        "# Step 6: Generate Recommendations\n",
        "# ============================\n",
        "userRecs = model.recommendForAllUsers(5)\n",
        "itemRecs = model.recommendForAllItems(5)\n",
        "\n",
        "print(\"\\n Top-5 movie recommendations for users:\")\n",
        "userRecs.select(\"userId\", \"recommendations\").show(5, truncate=False)\n",
        "\n",
        "# ============================\n",
        "# Step 7: Stop Spark\n",
        "# ============================\n",
        "spark.stop()\n"
      ]
    }
  ]
}